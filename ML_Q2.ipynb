{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Final Exam\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 Clustering Task (15 Marks):\n",
    "The \"Urban Mobility Patterns\" dataset provides insights into the daily commuting patterns of\n",
    "individuals in a metropolitan city. The dataset consists of 5,000 entries, 4 features (Average_Speed,\n",
    "Waiting_Time, Daily_Commute_Distance, Traffic_Congestion_Score) each representing an\n",
    "individual's daily mobility metrics. The objective is to cluster individuals based on these metrics to\n",
    "identify distinct mobility patterns and provide insights into urban transportation challenges.\n",
    "Perform the following tasks:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install minisom\n",
    "# %pip install scikit-learn==0.23.2\n",
    "# %pip install sompy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from sklearn.cluster import KMeans, DBSCAN, MeanShift, AgglomerativeClustering, OPTICS\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, silhouette_score\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "from minisom import MiniSom\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a.) Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data to the DataFrame\n",
    "df_ML_q2 = pd.read_excel('Urban_Mobility_Patterns_Data.xlsx')\n",
    "# df_ML_q2 = pd.read_csv('Urban_Mobility_Patterns_Data.csv)\n",
    "\n",
    "print(df_ML_q2.shape)\n",
    "df_ML_q2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ML_q2.describe()\n",
    "\n",
    "#df_ML_q2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the dataset\n",
    "df_ML_q2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the nature of missing values; \n",
    "# if the rows with missing value in 'Average_Speed' have missing values in 'Daily_Commute_Distance' as well.\n",
    "\n",
    "# Check if missing values in 'Average_Speed' correspond to missing values in 'Daily_Commute_Distance'\n",
    "missing_Average_Speed = df_ML_q2['Average_Speed'].isnull()\n",
    "missing_Daily_Commute_Distance = df_ML_q2['Daily_Commute_Distance'].isnull()\n",
    "\n",
    "# Check if all rows (index) with missing 'Average_Speed' also have missing 'Daily_Commute_Distance'\n",
    "all_missing_average_speed_have_missing_daily_commute_distance = missing_Average_Speed.equals(missing_Daily_Commute_Distance)\n",
    "\n",
    "# Print the result\n",
    "print(f\"All rows with missing 'Average_Speed' also missing 'Daily_Commute_Distance': {all_missing_average_speed_have_missing_daily_commute_distance}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use LinearRegression as the Imputation Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute the missing values\n",
    "\n",
    "\n",
    "# Columns to impute\n",
    "columns_to_impute = ['Average_Speed', 'Daily_Commute_Distance']\n",
    "\n",
    "# Create a copy of the DataFrame for imputation\n",
    "df_to_impute = df_ML_q2.copy()\n",
    "\n",
    "# Initialize variables to keep track of the best imputation\n",
    "best_imputation = None\n",
    "smallest_nulls = float('inf')  # Initialize with a large value\n",
    "\n",
    "# Loop through each column to impute\n",
    "for column in columns_to_impute:\n",
    "    # Identify features (independent variables) and target (variable to be imputed)\n",
    "    features = df_to_impute.drop(columns=columns_to_impute + ['Traffic_Congestion_Score', column])\n",
    "    target = df_to_impute[column]\n",
    "\n",
    "    # Identify missing values\n",
    "    missing_values = target.isnull()\n",
    "\n",
    "    # Split the dataset into known and unknown values\n",
    "    features_known = features[~missing_values]\n",
    "    features_unknown = features[missing_values]\n",
    "    target_known = target[~missing_values]\n",
    "\n",
    "    # Initialize a linear regression model\n",
    "    regression_model = LinearRegression()\n",
    "\n",
    "    # Use GridSearchCV to find the best parameters for imputation\n",
    "    param_grid = {'fit_intercept': [True, False]}\n",
    "    grid_search = GridSearchCV(regression_model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(features_known, target_known)\n",
    "\n",
    "    # Get the best model from GridSearchCV\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Predict the unknown values\n",
    "    imputed_values = best_model.predict(features_unknown)\n",
    "\n",
    "    # Update the DataFrame with imputed values\n",
    "    df_to_impute.loc[missing_values, column] = imputed_values\n",
    "\n",
    "    # Check the number of remaining null values\n",
    "    nulls = df_to_impute[columns_to_impute].isnull().sum().sum()\n",
    "\n",
    "    # Update the best imputation if the current one has fewer nulls\n",
    "    if nulls < smallest_nulls:\n",
    "        best_imputation = df_to_impute.copy()\n",
    "        smallest_nulls = nulls\n",
    "\n",
    "# Print the imputed DataFrame\n",
    "LR_grid_imputated = best_imputation\n",
    "print(\"Imputed DataFrame:\")\n",
    "print(LR_grid_imputated)\n",
    "# Verify the imputed DataFrame\n",
    "print(LR_grid_imputated.isnull().sum())\n",
    "print(LR_grid_imputated.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup for comparision between with GridSearch and Without"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ML_q2 = LR_grid_imputated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see the distribution of the features in the dataset, use the pairplot() function from the seaborn library.\n",
    "sns.pairplot(df_ML_q2, diag_kind = \"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and target variable\n",
    "X_q2 = df_ML_q2[['Average_Speed', 'Waiting_Time', 'Daily_Commute_Distance']]\n",
    "y_q2 = df_ML_q2['Traffic_Congestion_Score']\n",
    "\n",
    "feature_names = df_ML_q2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the features of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_q2_normalized = scaler.fit_transform(X_q2)\n",
    "# Check for NaN values in the normalized data\n",
    "\n",
    "if np.isnan(X_q2_normalized).any():\n",
    "    print(\"The normalized data contains NaN values. Please handle missing values.\")\n",
    "else:\n",
    "    print(\"The normalized data does not contain NaN values. Can continue with clustering.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for NaN values after normalizing features is a good practice for several reasons:\n",
    "\n",
    "Identification of Issues: NaN values in the data may indicate issues with the data preprocessing or feature engineering steps. It could be a result of missing values in the original dataset, and normalizing features with missing values might lead to unexpected or incorrect results.\n",
    "\n",
    "Impact on Models: Many machine learning algorithms, including clustering algorithms, may not handle NaN values well. The presence of NaN values in the data could cause errors during the training or evaluation of the models. By checking for NaN values, you can ensure that your data is in a suitable format for model training.\n",
    "\n",
    "Debugging: If NaN values are present, it helps in identifying where in the dataset they occur. This information is valuable for debugging and fixing the underlying issues in data preprocessing.\n",
    "\n",
    "Consistency: It ensures consistency in handling missing values throughout your data preprocessing pipeline. If NaN values are not handled properly during normalization, it might lead to unexpected behavior downstream in the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.) Model Building (5 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several machine learning models are commonly used for clustering, which is an unsupervised learning task aimed at grouping similar data points together. Here are some popular clustering algorithms:\n",
    "\n",
    "1) K-Means Clustering: Divides data into 'k' clusters based on centroids.\n",
    "    Pros: Simple, easy to understand, and computationally efficient.\n",
    "    Cons: Sensitive to initial centroids, assumes clusters are spherical.\n",
    "\n",
    "2) Hierarchical Clustering: Builds a hierarchy of clusters, either top-down (divisive) or bottom-up (agglomerative).\n",
    "    Pros: Provides a tree-like structure of clusters.\n",
    "    Cons: Computationally expensive for large datasets.\n",
    "\n",
    "3) DBSCAN (Density-Based Spatial Clustering of Applications with Noise): Groups together data points that are close to each other and have a sufficient number of neighbors.\n",
    "    Pros: Can find clusters of arbitrary shapes, robust to outliers.\n",
    "    Cons: Sensitive to parameters.\n",
    "\n",
    "4) Mean Shift: Aims to find dense regions in the data by iteratively shifting points towards the mode (peak) of the data distribution.\n",
    "    Pros: No need to specify the number of clusters, works well with various shapes.\n",
    "    Cons: Computationally expensive.\n",
    "\n",
    "5) Gaussian Mixture Model (GMM): Assumes that the data is generated from a mixture of several Gaussian distributions.\n",
    "    Pros: Provides probabilities of belonging to each cluster, flexible in terms of cluster covariance.\n",
    "    Cons: Sensitive to initialization.\n",
    "\n",
    "6) OPTICS (Ordering Points To Identify the Clustering Structure): An extension of DBSCAN that can discover clusters with varying densities.\n",
    "    Pros: Robust to noise and outliers.\n",
    "    Cons: Sensitive to parameters.\n",
    "\n",
    "7) Self-Organizing Maps (SOM): Neural network-based method that reduces dimensionality and projects data onto a 2D grid.\n",
    "    Pros: Can capture non-linear relationships, useful for visualization.\n",
    "    Cons: May require tuning of hyperparameters.\n",
    "    \n",
    "These algorithms cater to different types of data and structures, and the choice of which one to use often depends on the characteristics of the dataset and the goals of the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_q2_normalized, y_q2, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the shape of the training and test sets\n",
    "print(\"Shape of training set:\", X_train.shape)\n",
    "print(\"Shape of test set:\", X_test.shape)\n",
    "print(\"Shape of training labels:\", y_train.shape)\n",
    "print(\"Shape of test labels:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model K-Means\n",
    "\n",
    "\n",
    "# Create empty lists to store results for each model\n",
    "kmeans_results = []\n",
    "\n",
    "# 1) K-Means Clustering\n",
    "param_grid_kmeans = {'n_clusters': range(2, 11), 'n_init': [10]}\n",
    "best_silhouette_kmeans = float('-inf')\n",
    "best_num_clusters_kmeans = None\n",
    "best_labels_kmeans = None\n",
    "best_mse_kmeans = None\n",
    "best_mae_kmeans = None\n",
    "best_r2_kmeans = None\n",
    "\n",
    "for params_kmeans in ParameterGrid(param_grid_kmeans):\n",
    "    kmeans = KMeans(**params_kmeans)\n",
    "    labels_kmeans = kmeans.fit_predict(X_train)\n",
    "    silhouette_kmeans = silhouette_score(X_train, labels_kmeans)\n",
    "\n",
    "    # Assuming y_train is your target variable\n",
    "    y_pred_kmeans = kmeans.predict(X_train)\n",
    "\n",
    "    # Calculate metrics for training data\n",
    "    mse_kmeans = mean_squared_error(y_train, y_pred_kmeans)\n",
    "    mae_kmeans = mean_absolute_error(y_train, y_pred_kmeans)\n",
    "    r2_kmeans = r2_score(y_train, y_pred_kmeans)\n",
    "\n",
    "    if silhouette_kmeans > best_silhouette_kmeans:\n",
    "        best_silhouette_kmeans = silhouette_kmeans\n",
    "        best_num_clusters_kmeans = len(set(labels_kmeans))\n",
    "        best_labels_kmeans = labels_kmeans\n",
    "        best_mse_kmeans = mse_kmeans\n",
    "        best_mae_kmeans = mae_kmeans\n",
    "        best_r2_kmeans = r2_kmeans\n",
    "\n",
    "# Store K-Means results\n",
    "kmeans_results.append({\n",
    "    'model_name': 'K-Means Clustering',\n",
    "    'silhouette_score': best_silhouette_kmeans,\n",
    "    'num_clusters': best_num_clusters_kmeans,\n",
    "    'labels': best_labels_kmeans,\n",
    "    'mse': best_mse_kmeans,\n",
    "    'mae': best_mae_kmeans,\n",
    "    'r2': best_r2_kmeans\n",
    "})\n",
    "\n",
    "# Print results\n",
    "print(f\"Best Silhouette Score: {best_silhouette_kmeans}\")\n",
    "print(f\"Best Number of Clusters: {best_num_clusters_kmeans}\")\n",
    "print(f\"Best Mean Squared Error (MSE): {best_mse_kmeans}\")\n",
    "print(f\"Best Mean Absolute Error (MAE): {best_mae_kmeans}\")\n",
    "print(f\"Best R-squared (R2): {best_r2_kmeans}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot\n",
    "\n",
    "\n",
    "plt.figure(figsize=(13, 5))\n",
    "sns.scatterplot(x=X_train[:, 0], y=X_train[:, 1], hue=best_labels_kmeans, palette='viridis', legend='full')\n",
    "\n",
    "# Customize the plot with dynamic feature names and increase font size\n",
    "plt.title('K-Means Clustering Scatter Diagram for X_train', fontsize=16)\n",
    "plt.xlabel(feature_names[0], fontsize=14)  # Use the first feature name\n",
    "plt.ylabel(feature_names[3], fontsize=14)  # Use the second feature name    \n",
    "\n",
    "# Show the legend\n",
    "plt.legend(title='Cluster Label', bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=12)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box Plot over the features\n",
    "\n",
    "\n",
    "# Average_speed\n",
    "plt.figure(figsize=(10, 6))\n",
    "df_temp_kmeans_avg_speed = pd.DataFrame({'Cluster Label': best_labels_kmeans, 'Feature': X_train[:, 0]})\n",
    "sns.boxplot(x='Cluster Label', y='Feature', data=df_temp_kmeans_avg_speed, palette='viridis')\n",
    "plt.title('K-Means Clustering Box Plot for X_train - Average_Speed')\n",
    "plt.xlabel('Cluster Label')  \n",
    "plt.ylabel(feature_names[0])  # 0 = avg_speed\n",
    "plt.show()\n",
    "\n",
    "# Waiting time\n",
    "plt.figure(figsize=(10, 6))\n",
    "df_temp_kmeans_waiting_time = pd.DataFrame({'Cluster Label': best_labels_kmeans, 'Feature': X_train[:, 1]})\n",
    "sns.boxplot(x='Cluster Label', y='Feature', data=df_temp_kmeans_waiting_time, palette='viridis')\n",
    "plt.title('K-Means Clustering Box Plot for X_train - Waiting_Time')\n",
    "plt.xlabel('Cluster Label')  \n",
    "plt.ylabel(feature_names[1])  # 1 = waiting time\n",
    "plt.show()\n",
    "\n",
    "# Daily commute distance\n",
    "plt.figure(figsize=(10, 6))\n",
    "df_temp_kmeans_daily_commute = pd.DataFrame({'Cluster Label': best_labels_kmeans, 'Feature': X_train[:, 2]})\n",
    "sns.boxplot(x='Cluster Label', y='Feature', data=df_temp_kmeans_daily_commute, palette='viridis')\n",
    "plt.title('K-Means Clustering Box Plot for X_train - Daily_Commute_Distance')\n",
    "plt.xlabel('Cluster Label')\n",
    "plt.ylabel(feature_names[2])  # 2 = daily commute distance\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insights from the box plots:\n",
    "The normalization process scales features to a common range. This allows for a fair comparison between features with different units and magnitudes. We recognize a pattern in 2 major groups regarding avg_speed. One with higher average and one with lower than average. Clusters 0, 5 and 8 indicating more variability. Cluster 3 seems to have many outliers, also in daily commute distance. Regarding waiting time cluster 3 and 7 has the the largest spread.\n",
    "The interquartile range in cluster 3 is the biggest in any of the plots. Clusters illustrate differences in commute distances, people in different clusters tend to have varying commute distances. The spread of commute distances vary between clusters and Cluster 3 seems to have many outliers. Most of the clusters look quite similar in size. Since cluster 3 has many outliers it's hard to compare with the other clusters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster Distribution:\n",
    "\n",
    "\n",
    "# Plot Cluster Distribution\n",
    "sns.countplot(x='labels', data=pd.DataFrame({'labels': best_labels_kmeans}))\n",
    "plt.title('Cluster Distribution')\n",
    "plt.xlabel('Cluster Label')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Hierarchical Clustering model\n",
    "\n",
    "\n",
    "# Create empty lists to store results for each model\n",
    "hierarchical_results = []\n",
    "\n",
    "param_grid_hierarchical = {'n_clusters': range(2, 11)}\n",
    "best_silhouette_hierarchical = float('-inf')\n",
    "best_num_clusters_hierarchical = None\n",
    "best_labels_hierarchical = None\n",
    "best_mse_hierarchical = None\n",
    "best_mae_hierarchical = None\n",
    "best_r2_hierarchical = None\n",
    "\n",
    "for params_hierarchical in ParameterGrid(param_grid_hierarchical):\n",
    "    hierarchical = AgglomerativeClustering(**params_hierarchical)\n",
    "    labels_hierarchical = hierarchical.fit_predict(X_train)\n",
    "    silhouette_hierarchical = silhouette_score(X_train, labels_hierarchical)\n",
    "\n",
    "    # Assuming y_train is your target variable\n",
    "    y_pred_hierarchical = hierarchical.fit_predict(X_train)\n",
    "\n",
    "    # Calculate metrics for training data\n",
    "    mse_hierarchical = mean_squared_error(y_train, y_pred_hierarchical)\n",
    "    mae_hierarchical = mean_absolute_error(y_train, y_pred_hierarchical)\n",
    "    r2_hierarchical = r2_score(y_train, y_pred_hierarchical)\n",
    "\n",
    "    if silhouette_hierarchical > best_silhouette_hierarchical:\n",
    "        best_silhouette_hierarchical = silhouette_hierarchical\n",
    "        best_num_clusters_hierarchical = len(set(labels_hierarchical))\n",
    "        best_labels_hierarchical = labels_hierarchical\n",
    "        best_mse_hierarchical = mse_hierarchical\n",
    "        best_mae_hierarchical = mae_hierarchical\n",
    "        best_r2_hierarchical = r2_hierarchical\n",
    "\n",
    "# Store Hierarchical results\n",
    "hierarchical_results.append({\n",
    "    'model_name': 'Hierarchical Clustering',\n",
    "    'silhouette_score': best_silhouette_hierarchical,\n",
    "    'num_clusters': best_num_clusters_hierarchical,\n",
    "    'labels': best_labels_hierarchical,\n",
    "    'mse': best_mse_hierarchical,\n",
    "    'mae': best_mae_hierarchical,\n",
    "    'r2': best_r2_hierarchical\n",
    "})\n",
    "\n",
    "# Print results\n",
    "print(f\"Best Silhouette Score for Hierarchical Clustering: {best_silhouette_hierarchical}\")\n",
    "print(f\"Best Number of Clusters for Hierarchical Clustering: {best_num_clusters_hierarchical}\")\n",
    "print(f\"Best Mean Squared Error (MSE) for Hierarchical Clustering: {best_mse_hierarchical}\")\n",
    "print(f\"Best Mean Absolute Error (MAE) for Hierarchical Clustering: {best_mae_hierarchical}\")\n",
    "print(f\"Best R-squared (R2) for Hierarchical Clustering: {best_r2_hierarchical}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box plot - Hierarchical Clustering\n",
    "\n",
    "\n",
    "df_temp = pd.DataFrame(X_train, columns=['Average_Speed', 'Waiting_Time', 'Daily_Commute_Distance'])\n",
    "\n",
    "df_temp['Hierarchical_Cluster'] = best_labels_hierarchical\n",
    "\n",
    "# Plot box plots for each feature across Hierarchical Clusters\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.boxplot(data=df_temp.melt(id_vars='Hierarchical_Cluster'), x='Hierarchical_Cluster', y='value', hue='variable', showfliers=False)\n",
    "plt.title('Box Plots for Features Across Hierarchical Clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the scatter diagram with dynamic feature names for X_train\n",
    "\n",
    "\n",
    "# Choose the best result from Hierarchical Clustering\n",
    "best_hierarchical_result = hierarchical_results[0]\n",
    "\n",
    "# Plot the scatter diagram for Hierarchical Clustering\n",
    "plt.figure(figsize=(13, 5))\n",
    "sns.scatterplot(x=X_train[:, 0], y=X_train[:, 1], hue=best_hierarchical_result['labels'], palette='viridis', legend='full')\n",
    "plt.title('Hierarchical Clustering Scatter Diagram for X_train')\n",
    "plt.xlabel(feature_names[0])  # Use the first feature name\n",
    "plt.ylabel(feature_names[1])  # Use the second feature name\n",
    "\n",
    "# Add information about the model and evaluation metrics\n",
    "info_text = f\"Model: {best_hierarchical_result['model_name']}\\n\"\n",
    "info_text += f\"Number of Clusters: {best_hierarchical_result['num_clusters']}\\n\"\n",
    "info_text += f\"Silhouette Score: {best_hierarchical_result['silhouette_score']:.2f}\\n\"\n",
    "info_text += f\"Mean Squared Error (MSE): {best_hierarchical_result['mse']:.2f}\\n\"\n",
    "info_text += f\"Mean Absolute Error (MAE): {best_hierarchical_result['mae']:.2f}\\n\"\n",
    "info_text += f\"R-squared (R2): {best_hierarchical_result['r2']:.2f}\"\n",
    "\n",
    "# Show the legend\n",
    "plt.legend(title='Cluster Label', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) DBSCAN Clustering\n",
    "\n",
    "\n",
    "# Create empty lists to store results for each model\n",
    "dbscan_results = []\n",
    "\n",
    "# Define a range of parameters to search for DBSCAN\n",
    "param_grid_dbscan = {'eps': [0.1, 0.5, 1.0, 1.5], 'min_samples': [3, 5, 10, 15, 20]}\n",
    "cluster_range = range(2, 11)  # Range of cluster numbers to search for\n",
    "\n",
    "best_silhouette_dbscan = float('-inf')\n",
    "best_params_dbscan = {}\n",
    "best_labels_dbscan = None\n",
    "\n",
    "for params_dbscan in ParameterGrid(param_grid_dbscan):\n",
    "    for n_clusters in cluster_range:\n",
    "        dbscan = DBSCAN(**params_dbscan)\n",
    "        labels_dbscan = dbscan.fit_predict(X_q2_normalized)\n",
    "\n",
    "        # Check if the number of clusters found by DBSCAN is equal to the current iteration's cluster number\n",
    "        if len(set(labels_dbscan)) == n_clusters:\n",
    "            silhouette_dbscan = silhouette_score(X_q2_normalized, labels_dbscan)\n",
    "\n",
    "            if silhouette_dbscan > best_silhouette_dbscan:\n",
    "                best_silhouette_dbscan = silhouette_dbscan\n",
    "                best_params_dbscan = {**params_dbscan, 'n_clusters': n_clusters}\n",
    "                best_labels_dbscan = labels_dbscan\n",
    "\n",
    "# Append results to the list\n",
    "dbscan_results.append({\n",
    "    'model_name': 'DBSCAN Clustering',\n",
    "    'silhouette_score': best_silhouette_dbscan,\n",
    "    'num_clusters': best_params_dbscan['n_clusters'],\n",
    "    'params': best_params_dbscan\n",
    "})\n",
    "\n",
    "# Print the results\n",
    "for results in dbscan_results:\n",
    "    print(f\"{results['model_name']}: Silhouette Score - {results['silhouette_score']}, \\nNumber of Clusters - {results['num_clusters']}, Parameters - {results['params']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box plot - DBSCAN\n",
    "\n",
    "\n",
    "df_temp_dbscan = pd.DataFrame(X_q2, columns=['Average_Speed', 'Waiting_Time', 'Daily_Commute_Distance'])  # Adjust based on your data\n",
    "\n",
    "# Assuming best_labels_dbscan contains the optimal labels from DBSCAN Clustering\n",
    "best_labels_dbscan = best_labels_dbscan  # Use the actual variable name\n",
    "\n",
    "# Add the 'DBSCAN_Cluster' column to the temporary DataFrame using the best labels\n",
    "df_temp_dbscan['DBSCAN_Cluster'] = best_labels_dbscan\n",
    "\n",
    "# Plot box plots for each feature across DBSCAN Clusters\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.boxplot(data=df_temp_dbscan.melt(id_vars='DBSCAN_Cluster'), x='DBSCAN_Cluster', y='value', hue='variable', showfliers=False)\n",
    "plt.title('Box Plots for Features Across DBSCAN Clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output shows that DBSCAN is consistently finding 6 clusters, but the silhouette score varies slightly. The silhouette score is a measure of how similar an object is to its own cluster compared to other clusters. It ranges from -1 to 1, where a high value indicates that the object is well matched to its own cluster and poorly matched to neighboring clusters.\n",
    "\n",
    "In your case, the slight variation in silhouette scores might be due to the sensitivity of the silhouette score to the local structure of the data. Different runs of the algorithm may result in slightly different assignments of points to clusters, leading to small variations in silhouette scores.\n",
    "\n",
    "Additionally, the silhouette score itself is not always a definitive measure, and its interpretation can depend on the nature of the data. It's often a good practice to consider other evaluation metrics and, in some cases, to visually inspect the clustering results to make a more informed assessment.\n",
    "\n",
    "If you're consistently getting 6 clusters with similar silhouette scores, it indicates a stable clustering structure for your data with DBSCAN. However, if you're looking for more consistency, you might want to explore other clustering algorithms or fine-tune the parameters further to see if you can achieve a more stable result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Plot - DBSCAN Clustering\n",
    "\n",
    "\n",
    "# Choose the best result from DBSCAN Clustering\n",
    "best_dbscan_result = dbscan_results[0]\n",
    "\n",
    "# Plot the scatter diagram for DBSCAN Clustering\n",
    "plt.figure(figsize=(13, 5))\n",
    "sns.scatterplot(x=X_q2_normalized[:, 0], y=X_q2_normalized[:, 1], hue=best_labels_dbscan, palette='viridis', legend='full')\n",
    "plt.title('DBSCAN Clustering Scatter Diagram')\n",
    "plt.xlabel(feature_names[0]) \n",
    "plt.ylabel(feature_names[1]) \n",
    "\n",
    "# Add information about the model and evaluation metrics\n",
    "info_text = f\"Model: {best_dbscan_result['model_name']}\\n\"\n",
    "info_text += f\"Number of Clusters: {best_dbscan_result['num_clusters']}\\n\"\n",
    "info_text += f\"Silhouette Score: {best_dbscan_result['silhouette_score']:.2f}\\n\"\n",
    "info_text += f\"Parameters: {best_dbscan_result['params']}\"\n",
    "\n",
    "# Show the legend\n",
    "plt.legend(title='Cluster Label', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Mean Shift Clustering Model. This can take up to 3 minutes to run\n",
    "\n",
    "\n",
    "# Create empty lists to store results for each model\n",
    "mean_shift_results = []\n",
    "\n",
    "# Function to find the best Mean Shift Clustering model\n",
    "def find_best_mean_shift(X, param_grid):\n",
    "    best_model = None\n",
    "    best_silhouette = float('-inf')\n",
    "    best_params = None\n",
    "\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        mean_shift = MeanShift(**params)\n",
    "        labels = mean_shift.fit_predict(X)\n",
    "\n",
    "        # Check if the number of clusters found by Mean Shift is greater than 1\n",
    "        if len(set(labels)) > 1:\n",
    "            silhouette = silhouette_score(X, labels)\n",
    "\n",
    "            # Update the best model if the silhouette score is higher\n",
    "            if silhouette > best_silhouette:\n",
    "                best_silhouette = silhouette\n",
    "                best_model = mean_shift\n",
    "                best_params = params\n",
    "\n",
    "    return best_model, best_silhouette, best_params\n",
    "\n",
    "# Define the parameter grid for Mean Shift Clustering\n",
    "param_grid_mean_shift = {'bandwidth': [0.1, 0.5, 1.0, 1.5]}\n",
    "\n",
    "# Find the best Mean Shift Clustering model\n",
    "best_mean_shift_model, best_silhouette_mean_shift, best_params_mean_shift = find_best_mean_shift(X_q2_normalized, param_grid_mean_shift)\n",
    "\n",
    "# Store Mean Shift results\n",
    "mean_shift_results.append({\n",
    "    'model_name': 'Mean Shift Clustering',\n",
    "    'silhouette_score': best_silhouette_mean_shift,\n",
    "    'num_clusters': len(set(best_mean_shift_model.labels_)),\n",
    "    'params': best_params_mean_shift\n",
    "    })\n",
    "\n",
    "# Print the results\n",
    "print(\"Best Mean Shift Clustering with Silhouette Score:\", best_silhouette_mean_shift)\n",
    "print(\"Best Parameters for Mean Shift Clustering:\", best_params_mean_shift)\n",
    "\n",
    "# Output the number of clusters\n",
    "num_clusters_mean_shift = len(set(best_mean_shift_model.labels_))\n",
    "print(\"Number of Clusters:\", num_clusters_mean_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box plot - Mean Shift Clustering Model \n",
    "\n",
    "\n",
    "# Assuming X_q2 is your original feature matrix with 3 columns\n",
    "df_temp_mean_shift = pd.DataFrame(X_q2, columns=['Average_Speed', 'Waiting_Time', 'Daily_Commute_Distance'])  # Adjust based on your data\n",
    "\n",
    "# Assuming best_mean_shift_model.labels_ contains the optimal labels from Mean Shift Clustering\n",
    "best_labels_mean_shift = best_mean_shift_model.labels_  # Use the actual variable name\n",
    "\n",
    "# Add the 'Mean_Shift_Cluster' column to the temporary DataFrame using the best labels\n",
    "df_temp_mean_shift['Mean_Shift_Cluster'] = best_labels_mean_shift\n",
    "\n",
    "# Plot box plots for each feature across Mean Shift Clusters\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.boxplot(data=df_temp_mean_shift.melt(id_vars='Mean_Shift_Cluster'), x='Mean_Shift_Cluster', y='value', hue='variable', showfliers=False)\n",
    "plt.title('Box Plots for Features Across Mean Shift Clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the scatter diagram for Mean Shift Clustering with different colors for each cluster\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x=X_q2_normalized[:, 0], y=X_q2_normalized[:, 1], hue=best_mean_shift_model.labels_, palette='muted',legend='full', marker='o')\n",
    "plt.title('Mean Shift Clustering Scatter Diagram')\n",
    "plt.xlabel(feature_names[0])\n",
    "plt.ylabel(feature_names[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Gaussian Mixture Model (GMM)  \n",
    "\n",
    "\n",
    "# Create empty lists to store results for each model\n",
    "gmm_results = []\n",
    "\n",
    "# Function to find the best Gaussian Mixture Model\n",
    "def find_best_gmm(X, param_grid):\n",
    "    best_model = None\n",
    "    best_silhouette = float('-inf')\n",
    "    best_params = None\n",
    "\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        gmm = GaussianMixture(**params)\n",
    "        labels = gmm.fit_predict(X)\n",
    "\n",
    "        # Check if the number of clusters found by GMM is greater than 1\n",
    "        if len(set(labels)) > 1:\n",
    "            silhouette = silhouette_score(X, labels)\n",
    "\n",
    "            # Update the best model if the silhouette score is higher\n",
    "            if silhouette > best_silhouette:\n",
    "                best_silhouette = silhouette\n",
    "                best_model = gmm\n",
    "                best_params = params\n",
    "\n",
    "    return best_model, best_silhouette, best_params\n",
    "\n",
    "# Disable ConvergenceWarnings\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "# Define the parameter grid for Gaussian Mixture Model\n",
    "param_grid_gmm = {'n_components': range(2, 11)}\n",
    "\n",
    "# Find the best Gaussian Mixture Model\n",
    "best_gmm_model, best_silhouette_gmm, best_params_gmm = find_best_gmm(X_q2_normalized, param_grid_gmm)\n",
    "\n",
    "# Re-enable warnings\n",
    "warnings.filterwarnings(\"default\", category=ConvergenceWarning)\n",
    "\n",
    "# Store GMM results\n",
    "gmm_results.append({\n",
    "    'model_name': 'Gaussian Mixture Model',\n",
    "    'silhouette_score': best_silhouette_gmm,\n",
    "    'num_clusters': best_gmm_model.n_components,\n",
    "    'params': best_params_gmm\n",
    "})\n",
    "\n",
    "# Print the results\n",
    "print(\"Best Gaussian Mixture Model with Silhouette Score:\", best_silhouette_gmm)\n",
    "print(\"Best Parameters for Gaussian Mixture Model:\", best_params_gmm)\n",
    "print(\"Number of Clusters:\", best_gmm_model.n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box plot for Gaussian Mixture Model (GMM) \n",
    "\n",
    "\n",
    "df_temp_gmm = pd.DataFrame(X_q2, columns=['Average_Speed', 'Waiting_Time', 'Daily_Commute_Distance'])\n",
    "\n",
    "# use the best labels from gmm\n",
    "best_labels_gmm = best_gmm_model.predict(X_q2_normalized)\n",
    "\n",
    "# Add the 'GMM_Cluster' column to the temporary DataFrame using the best labels\n",
    "df_temp_gmm['GMM_Cluster'] = best_labels_gmm\n",
    "\n",
    "# Plot box plots for each feature across GMM Clusters\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.boxplot(data=df_temp_gmm.melt(id_vars='GMM_Cluster'), x='GMM_Cluster', y='value', hue='variable', showfliers=False)\n",
    "plt.title('Box Plots for Features Across GMM Clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the scatter diagram for the best Gaussian Mixture Model with different colors for each cluster\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x=X_q2_normalized[:, 0], y=X_q2_normalized[:, 1], hue=best_gmm_model.predict(X_q2_normalized), palette='muted', marker='o')\n",
    "plt.title('Gaussian Mixture Model Clustering Scatter Diagram')\n",
    "plt.xlabel(feature_names[0])\n",
    "plt.ylabel(feature_names[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) OPTICS Clustering\n",
    "\n",
    "\n",
    "# Create empty lists to store results for each model\n",
    "optics_results = []\n",
    "\n",
    "# Define a range of parameters to search for OPTICS\n",
    "param_grid_optics = {'min_samples': [3, 5, 7, 10], 'xi': [0.01, 0.05, 0.1, 0.2]}\n",
    "best_silhouette_optics = float('-inf')\n",
    "best_params_optics = {}\n",
    "\n",
    "for params_optics in ParameterGrid(param_grid_optics):\n",
    "    optics = OPTICS(**params_optics)\n",
    "    labels_optics = optics.fit_predict(X_q2_normalized)\n",
    "\n",
    "    # Check if OPTICS found more than one cluster\n",
    "    unique_labels_optics = set(labels_optics)\n",
    "    if len(unique_labels_optics) > 1:\n",
    "        silhouette_optics = silhouette_score(X_q2_normalized, labels_optics)\n",
    "\n",
    "        if silhouette_optics > best_silhouette_optics:\n",
    "            best_silhouette_optics = silhouette_optics\n",
    "            best_params_optics = params_optics\n",
    "\n",
    "# Store OPTICS results\n",
    "optics_results = [{\n",
    "    'model_name': 'OPTICS Clustering1',\n",
    "    'silhouette_score': best_silhouette_optics,\n",
    "    'num_clusters': len(unique_labels_optics),\n",
    "    'params': best_params_optics\n",
    "}]\n",
    "\n",
    "# Print the results\n",
    "for results in optics_results:\n",
    "    params_str = results.get('params', {}) \n",
    "    print(f\"{results['model_name']}: Silhouette Score - {results['silhouette_score']}, Number of Clusters - {results['num_clusters']}, Parameters - {params_str}\")\n",
    "    print(f\"Number of Clusters: {results['num_clusters']}\")\n",
    "\n",
    "# Plot the OPTICS clustering scatter diagram with 'muted' colormap\n",
    "plt.figure(figsize=(12, 6))\n",
    "palette = sns.color_palette(\"muted\", n_colors=len(unique_labels_optics))\n",
    "sns.scatterplot(x=X_q2_normalized[:, 0], y=X_q2_normalized[:, 1], hue=labels_optics, palette=palette, marker='o')\n",
    "\n",
    "plt.title('OPTICS Clustering Scatter Diagram')\n",
    "plt.xlabel(feature_names[0])\n",
    "plt.ylabel(feature_names[1])\n",
    "plt.legend(title='Cluster Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The OPTICS clustering algorithm is designed to discover density-based clusters in data. The silhouette score is a measure of how well-defined the clusters are, with a higher silhouette score indicating better-defined clusters. In your case, the silhouette score is negative, and the number of clusters is very high (696). This suggests that OPTICS is not performing well on your data, and the resulting clusters may not be meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box plot for optics\n",
    "\n",
    "\n",
    "df_temp_optics = pd.DataFrame(X_q2, columns=['Average_Speed', 'Waiting_Time', 'Daily_Commute_Distance'])  # Adjust based on your data\n",
    "\n",
    "# Best_labels_optics contains the optimal labels from OPTICS Clustering\n",
    "best_labels_optics = labels_optics\n",
    "\n",
    "# Add the 'OPTICS_Cluster' column to the temporary DataFrame using the best labels\n",
    "df_temp_optics['OPTICS_Cluster'] = best_labels_optics\n",
    "\n",
    "# Plot box plots for each feature across OPTICS Clusters\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.boxplot(data=df_temp_optics.melt(id_vars='OPTICS_Cluster'), x='OPTICS_Cluster', y='value', hue='variable', showfliers=False)\n",
    "plt.title('Box Plots for Features Across OPTICS Clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPTICS (Ordering Points To Identify the Clustering Structure) is generally not very sensitive to the scale of the features, so it can work on both normalized and unnormalized data. Normalization, which scales features to a standard range, is often recommended for many clustering algorithms to ensure that all features contribute equally to the distance calculations.\n",
    "\n",
    "However, OPTICS has an inherent ability to handle data with varying densities, making it less sensitive to the scale of features compared to some other clustering algorithms. Therefore, while normalization might still be beneficial in some cases, OPTICS may perform reasonably well on unnormalized data.\n",
    "\n",
    "As a good practice, it's recommended to try both normalized and unnormalized data and observe the performance to determine the most suitable approach for your specific dataset. Keep in mind that the optimal preprocessing steps can vary depending on the characteristics of the data and the specific requirements of your clustering task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizing the OPTICS Clustering Model\n",
    "\n",
    "# 7) Self-Organizing Maps (SOM) Optimization\n",
    "\n",
    "# Create empty lists to store results for each model\n",
    "som_results = []\n",
    "\n",
    "# Define the parameter grid for SOM\n",
    "param_grid_som = {\n",
    "    'x': [5, 10, 15],\n",
    "    'y': [5, 10, 15],\n",
    "    'input_len': [X_q2_normalized.shape[1]],\n",
    "    'sigma': [0.5, 1.0, 1.5],\n",
    "    'learning_rate': [0.1, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "best_silhouette_som = float('-inf')\n",
    "best_params_som = {}\n",
    "\n",
    "# Perform grid search\n",
    "for params_som in ParameterGrid(param_grid_som):\n",
    "    som = MiniSom(**params_som)\n",
    "    som.train_random(X_q2_normalized, 100)\n",
    "    labels_som = np.array([som.winner(x) for x in X_q2_normalized]).T[0]\n",
    "    silhouette_som = silhouette_score(X_q2_normalized, labels_som)\n",
    "\n",
    "    # Update the best results if the silhouette score is higher\n",
    "    if silhouette_som > best_silhouette_som:\n",
    "        best_silhouette_som = silhouette_som\n",
    "        best_params_som = params_som\n",
    "\n",
    "# Store SOM results\n",
    "som_results.append({\n",
    "    'model_name': 'Self-Organizing Maps Optimized',\n",
    "    'silhouette_score': best_silhouette_som,\n",
    "    'num_clusters': len(set(labels_som)),\n",
    "    'params': best_params_som\n",
    "})\n",
    "\n",
    "# Print the optimized results\n",
    "print(f\"Optimized SOM Model: Silhouette Score - {best_silhouette_som}\")\n",
    "print(f\"Number of Clusters - {len(set(labels_som))}\")\n",
    "print(f\"Model Parameters - {best_params_som}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists to store results for each model\n",
    "som_results = []\n",
    "\n",
    "# Parameters for MiniSom\n",
    "som = MiniSom(x=10, y=10, input_len=X_q2_normalized.shape[1], sigma=1.0, learning_rate=0.5)\n",
    "som.train_random(X_q2_normalized, 100)  # Adjust the number of iterations as needed\n",
    "labels_som = np.array([som.winner(x) for x in X_q2_normalized]).T[0]\n",
    "\n",
    "# Calculate silhouette score for SOM\n",
    "silhouette_som = silhouette_score(X_q2_normalized, labels_som)\n",
    "\n",
    "# Store SOM results\n",
    "som_results.append({\n",
    "    'model_name': 'Self-Organizing Maps01',\n",
    "    'silhouette_score': silhouette_som,\n",
    "    'num_clusters': len(set(labels_som)),\n",
    "})\n",
    "\n",
    "# Print the optimized results\n",
    "print(f\"Optimized SOM Model: Silhouette Score - {silhouette_som}\")\n",
    "print(f\"Number of Clusters - {len(set(labels_som))}\")\n",
    "print(f\"Model Parameters - {som_results[0]['model_name']}\")\n",
    "\n",
    "\n",
    "# Plot the scatter diagram with the 'muted' color palette\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x=X_q2_normalized[:, 0], y=X_q2_normalized[:, 1], hue=labels_som, palette='muted', marker='o')\n",
    "plt.title('Self-Organizing Maps Scatter Diagram')\n",
    "plt.xlabel(feature_names[0])\n",
    "plt.ylabel(feature_names[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all results into a single list\n",
    "all_results = (\n",
    "    kmeans_results + hierarchical_results + dbscan_results +\n",
    "    mean_shift_results + gmm_results + optics_results + som_results\n",
    ")\n",
    "\n",
    "# Print the results\n",
    "for results in all_results:\n",
    "    print(f\"{results['model_name']}: Silhouette Score - {results['silhouette_score']}, Number of Clusters - {results['num_clusters']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it's quite normal to observe different results, including varying silhouette scores and numbers of clusters, when applying different clustering algorithms to the same dataset. Different clustering algorithms make different assumptions about the structure of the data and have different strengths and weaknesses. The choice of the most appropriate algorithm depends on the characteristics of the data and the goals of your analysis.\n",
    "\n",
    "Here are some factors that can contribute to these differences:\n",
    "\n",
    "Algorithm Assumptions: Clustering algorithms have different assumptions about the shape and distribution of clusters. K-Means, for example, assumes spherical clusters, while DBSCAN can find clusters of arbitrary shapes. These assumptions can lead to different interpretations of the underlying structure of the data.\n",
    "\n",
    "Parameter Sensitivity: Clustering algorithms often have parameters that need to be set, such as the number of clusters for K-Means or the epsilon and min_samples for DBSCAN. The choice of these parameters can significantly impact the results.\n",
    "\n",
    "Handling of Outliers: Algorithms like DBSCAN can identify outliers as noise points, while others like K-Means may assign outliers to the nearest cluster. This can result in different cluster compositions and silhouette scores.\n",
    "\n",
    "Topology and Density Considerations: Algorithms like OPTICS can handle clusters with varying shapes and densities, which may lead to different outcomes compared to algorithms with rigid assumptions about cluster geometry.\n",
    "\n",
    "Feature Scaling: Some algorithms are sensitive to the scale of features, so standardizing or normalizing the data may affect results.\n",
    "\n",
    "Given these variations, it's common practice to try multiple clustering algorithms and compare their results. Silhouette score and the number of clusters are just two metrics among many that you can use to evaluate the quality of the clustering. It's essential to consider the context of your data and the goals of your analysis when choosing the most appropriate algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar grapgh - Silhouette scores the models that does not support mse, mae and r2\n",
    "\n",
    "\n",
    "# Find the index of the model with the highest silhouette score\n",
    "max_silhouette_index = max(range(len(all_results)), key=lambda i: all_results[i]['silhouette_score'])\n",
    "\n",
    "# Convert the results to a DataFrame for easier plotting\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create a horizontal barplot with the number of clusters\n",
    "ax = sns.barplot(x='num_clusters', y='model_name', data=results_df, palette=\"Blues\")\n",
    "\n",
    "# Overlay the silhouette scores on the bars\n",
    "for index, value in enumerate(results_df['num_clusters']):\n",
    "    text_color = 'white' if index == max_silhouette_index else 'black'  # Adjust text color for better visibility\n",
    "    ax.text(value + 0.1, index, f\"{results_df['silhouette_score'][index]:.3f}\", va='center', color=text_color)\n",
    "\n",
    "# Change the color of the bar for the model with the highest silhouette score to red\n",
    "ax.patches[max_silhouette_index].set_facecolor('red')\n",
    "\n",
    "# Display the silhouette score on the bar with the highest silhouette score\n",
    "ax.text(results_df['num_clusters'][max_silhouette_index] + 0.1, max_silhouette_index,\n",
    "        f\"{results_df['silhouette_score'][max_silhouette_index]:.3f}\", va='center', color='red')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Number of Clusters and Silhouette Scores for Clustering Models')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Clustering Model')\n",
    "plt.tight_layout()\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the models who support mse, mae and r2\n",
    "\n",
    "\n",
    "# Set a seaborn style with shades of blue\n",
    "sns.set_palette(\"BuPu\")\n",
    "\n",
    "# Example results list (replace this with your actual results for both K-Means and Hierarchical Clustering)\n",
    "results_list = [\n",
    "    {'model_name': 'K-Means Clustering', 'mse': 0.1, 'mae': 0.08, 'r2': 0.9},\n",
    "    {'model_name': 'Hierarchical Clustering', 'mse': 0.15, 'mae': 0.12, 'r2': 0.85},\n",
    "    # Add more models and their metrics as needed\n",
    "]\n",
    "\n",
    "# Extract model names and relevant metrics\n",
    "model_names = [result['model_name'] for result in results_list]\n",
    "mse_values = [result['mse'] for result in results_list]\n",
    "mae_values = [result['mae'] for result in results_list]\n",
    "r2_values = [result['r2'] for result in results_list]\n",
    "\n",
    "# Create a horizontal bar chart with reduced separation between top and bottom groups\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "bar_width = 0.2  # Adjust the width of each bar\n",
    "separation_top = 0.22  # Adjust the separation for the top three bars\n",
    "separation_bottom = 0.22  # Adjust the separation for the bottom three bars\n",
    "\n",
    "index = np.arange(len(model_names))\n",
    "\n",
    "bar_mse = ax.barh(index - separation_top, mse_values, bar_width, label='Mean Squared Error (MSE)')\n",
    "bar_mae = ax.barh(index, mae_values, bar_width, label='Mean Absolute Error (MAE)')\n",
    "bar_r2 = ax.barh(index + separation_bottom, r2_values, bar_width, label='R-squared (R2)')\n",
    "\n",
    "# Add values on the bars\n",
    "for i, value in enumerate(mse_values):\n",
    "    ax.text(value + 0.02, index[i] - separation_top, f'{value:.2f}', va='center', ha='left')\n",
    "\n",
    "\n",
    "for i, value in enumerate(mae_values):\n",
    "    ax.text(value + 0.02, index[i], f'{value:.2f}', va='center', ha='left')\n",
    "\n",
    "\n",
    "for i, value in enumerate(r2_values):\n",
    "    ax.text(value + 0.02, index[i] + separation_bottom, f'{value:.2f}', va='center', ha='left')\n",
    "\n",
    "# Add labels, title, and legend\n",
    "ax.set_yticks(index)\n",
    "ax.set_yticklabels(model_names)\n",
    "ax.set_xlabel('Metrics')\n",
    "ax.set_title('Comparison Across Models')\n",
    "\n",
    "# Reverse the order of legends to be in the same order as the bars\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[::-1], labels[::-1], bbox_to_anchor=(0.65, 0.8), loc='upper left')  # Adjust position here\n",
    "\n",
    "ax.set_xlim(0, 1.0)\n",
    "# Show the plot\n",
    "plt.show()\n",
    "#plt.savefig('mse_mae_and_r2.png') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
