{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63374905",
   "metadata": {},
   "source": [
    "### Natural Language Processing Final Exam\n",
    "#### Question 1) Text processing, feature extraction and representation by using both TF and TF-IDF schemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc5477d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install Pillow\n",
    "#%pip install --upgrade Pillow\n",
    "#%pip install WordCloud\n",
    "#%pip install --upgrade WordCloud\n",
    "#%pip uninstall Pillow\n",
    "#%pip install --upgrade Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00aa93ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "import string\n",
    "import warnings\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD, NMF\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46248c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data: Exam_NLP.csv\n",
    "df = pd.read_csv('Exam_NLP.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be5aa7d",
   "metadata": {},
   "source": [
    "### Task 1: Data Preprocessing\n",
    "#### Access the columns, then through printing and visualization, understand the meaning in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad868d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a working DataFrame for Question 1.\n",
    "df_NLP_q1 = df.copy()\n",
    "print(df_NLP_q1.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71c1cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'release_date' to datetime\n",
    "df_NLP_q1['release_date'] = pd.to_datetime(df_NLP_q1['release_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f527b284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique original languages.\n",
    "df_NLP_q1['original_language'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d203ad3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the counts of movies based on unique 'original_language'\n",
    "language_counts = df_NLP_q1['original_language'].value_counts().reset_index()\n",
    "language_counts.columns = ['Original Language', 'Number of Movies']\n",
    "\n",
    "# Display the table\n",
    "print(language_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5f4534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot -  top 10 languages\n",
    "\n",
    "\n",
    "language_counts = df_NLP_q1['original_language'].value_counts()\n",
    "top_language = language_counts.idxmax()\n",
    "top_languages = language_counts.nlargest(10).index\n",
    "\n",
    "# Set the style for the plot\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "\n",
    "# Set up subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=(18, 8), gridspec_kw={'width_ratios': [1, 4]})\n",
    "\n",
    "# Plot for the top language\n",
    "sns.countplot(x='original_language', data=df_NLP_q1[df_NLP_q1['original_language'] == top_language], palette='viridis', ax=axs[0])\n",
    "axs[0].set_title(f'{top_language.capitalize()} ({len(df_NLP_q1[df_NLP_q1[\"original_language\"] == top_language])})', fontsize=16)\n",
    "\n",
    "# Plot for the other nine languages (excluding 'en')\n",
    "sns.countplot(x='original_language', data=df_NLP_q1[df_NLP_q1['original_language'].isin(top_languages) & (df_NLP_q1['original_language'] != 'en')], palette='viridis', order=top_languages, ax=axs[1])\n",
    "axs[1].set_title('Other Languages', fontsize=16)\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "axs[1].tick_params(axis='x', rotation=90, labelsize=14)  # Increase x-axis label font size\n",
    "\n",
    "# Add numbers on the bars\n",
    "for ax in axs:\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='baseline', fontsize=20)\n",
    "\n",
    "# Add labels and title\n",
    "fig.suptitle('Top 10 Original Languages', fontsize=18)\n",
    "# axs[0].set_ylabel('Number of Movies')\n",
    "# axs[1].set_ylabel('Number of Movies')\n",
    "# axs[1].set_xlabel('Original Language')\n",
    "\n",
    "axs[0].tick_params(axis='y', labelsize=14)\n",
    "axs[1].tick_params(axis='y', labelsize=14)\n",
    "\n",
    "# Remove the empty space for the 'en' bar\n",
    "axs[1].margins(x=0)\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc03baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the display format for float values to be in standard decimal notation\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "# print as decimal\n",
    "revenue_stats = df_NLP_q1['revenue'].describe()\n",
    "print(revenue_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf556ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot - Average Budget and Revenue Over Release Years with Variance Shadows\n",
    "\n",
    "\n",
    "# Convert release_date to datetime\n",
    "df_NLP_q1['release_date'] = pd.to_datetime(df_NLP_q1['release_date'])\n",
    "\n",
    "# Extract release year\n",
    "df_NLP_q1['release_year'] = df_NLP_q1['release_date'].dt.year\n",
    "\n",
    "# Set the style for the plot\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Create a line plot with shadows for average budget\n",
    "sns.lineplot(x='release_year', y='budget', data=df_NLP_q1, label='Average Budget', err_style=\"band\", lw=2, errorbar='sd')\n",
    "\n",
    "# Create a line plot with shadows for average revenue\n",
    "sns.lineplot(x='release_year', y='revenue', data=df_NLP_q1, label='Average Revenue', err_style=\"band\", lw=2, errorbar='sd')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Release Year')\n",
    "plt.ylabel('Amount (in billions)')\n",
    "plt.title('Average Budget and Revenue Over Release Years with Variance Shadows')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0ab59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot - Average Budget and Revenue Over Release Years with Min-Max Shadows\n",
    "\n",
    "\n",
    "# Convert release_date to datetime\n",
    "df_NLP_q1['release_date'] = pd.to_datetime(df_NLP_q1['release_date'])\n",
    "\n",
    "# Extract release year\n",
    "df_NLP_q1['release_year'] = df_NLP_q1['release_date'].dt.year\n",
    "\n",
    "# Set the style for the plot\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Create a line plot with shadows for average budget\n",
    "sns.lineplot(x='release_year', y='budget', data=df_NLP_q1, label='Average Budget', err_style=\"band\", lw=2, errorbar=None)\n",
    "sns.lineplot(x='release_year', y='budget', data=df_NLP_q1, err_style=\"band\", alpha=0.2, errorbar='sd', color='blue')\n",
    "\n",
    "# Create a line plot with shadows for average revenue\n",
    "sns.lineplot(x='release_year', y='revenue', data=df_NLP_q1, label='Average Revenue', err_style=\"band\", lw=2, errorbar=None)\n",
    "sns.lineplot(x='release_year', y='revenue', data=df_NLP_q1, err_style=\"band\", alpha=0.2, errorbar='sd', color='orange')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Release Year')\n",
    "plt.ylabel('Amount (in billions)')\n",
    "plt.title('Average Budget and Revenue Over Release Years with Min-Max Shadows')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9eb1944",
   "metadata": {},
   "source": [
    "### Then create a new column, name it as ‘description’ by concatenating the strings from two columns: tagline and overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94537546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing value in 'tagline' and 'overview' columns\n",
    "df_NLP_q1[['tagline', 'overview']].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcb65df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the shape of the DataFrame  \n",
    "print(df_NLP_q1.shape)\n",
    "df_NLP_q1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce71ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there is any rows with missing values in both columns\n",
    "df_NLP_q1[['tagline', 'overview']].isnull().all(axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a494ba4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 'description' column from 'tagline' and 'overview', dropping rows with missing values in BOTH columns\n",
    "\n",
    "# Drop rows with missing values in both 'tagline' and 'overview' columns\n",
    "df_NLP_q1 = df_NLP_q1.dropna(subset=['tagline', 'overview'], how='all')\n",
    "\n",
    "# Create the 'description' column\n",
    "df_NLP_q1['description'] = df_NLP_q1['tagline'].astype(str) + ' ' + df_NLP_q1['overview'].astype(str)\n",
    "\n",
    "# Check for the shape of the DataFrame\n",
    "print(df_NLP_q1.shape)\n",
    "\n",
    "# Display the head of the 'description' column\n",
    "print(df_NLP_q1['description'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2be2c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in 'description' column\n",
    "df_NLP_q1['description'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bfa2d1",
   "metadata": {},
   "source": [
    "### Task 2: Text Preprocessing\n",
    "#### convert words in ‘description’ to lower case, remove white space, remove words from stop_words (from nltk package), remove special characters (such as ‘/n’) and add other necessary processings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725739f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a text_processing function.\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def process_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove white spaces\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    # Remove stop words\n",
    "    text = ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
    "    \n",
    "    # Remove special characters\n",
    "    text = ''.join([char for char in text if char not in string.punctuation])\n",
    "    \n",
    "    # Remove numbers\n",
    "    text = ''.join([char for char in text if not char.isdigit()])\n",
    "    \n",
    "    # Lemmatize using WordNetLemmatizer\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "    \n",
    "    # Remove NaNs\n",
    "    text = text.replace('nan', '')\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply text processing to the 'description' column\n",
    "df_NLP_q1['processed_description'] = df_NLP_q1['description'].apply(process_text)\n",
    "\n",
    "# Check the shape of the DataFrame\n",
    "print(df_NLP_q1.shape)\n",
    "\n",
    "# Output 15 rows of the modified dataframe\n",
    "print(df_NLP_q1[['processed_description']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3961c8b",
   "metadata": {},
   "source": [
    "### Taks 3: TF and TF-IDF representation on ‘description’: for each sample in the dataset, generate TF and TF-IDF representation for each sample based on the column of ‘description’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09943f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tf vector\n",
    "\n",
    "\n",
    "# To summarize the attributes of the DataFram\n",
    "movie_descriptions = df_NLP_q1['processed_description'].copy()\n",
    "n_samples = movie_descriptions.shape[0] # Number of samples (documents)\n",
    "n_features = 3000  # Size of vocabulary, can set the desired number of features\n",
    "\n",
    "count_vectorizer = CountVectorizer(\n",
    "    # max_df=0.95, min_df=2, max_features=n_features, stop_words=\"english\"\n",
    "    max_features=n_features, stop_words=\"english\"\n",
    ")\n",
    "# Join the tokenized words into a single string for each document\n",
    "tf_vector = count_vectorizer.fit_transform(movie_descriptions)\n",
    "tf_feature_names = count_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Explore the TF vectors\n",
    "print(type(tf_vector))\n",
    "print(tf_vector.shape)\n",
    "print(tf_feature_names[:50])\n",
    "print(tf_vector.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f83e891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF vectors\n",
    "\n",
    "\n",
    "movie_descriptions = df_NLP_q1['processed_description'].copy()\n",
    "n_samples = movie_descriptions.shape[0] # Number of samples (documents)\n",
    "n_features = 3000  # Size of vocabulary, can set the desired number of features\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "     # max_df=0.95, min_df=2, max_features=n_features, stop_words=\"english\"\n",
    "    max_features=n_features, stop_words=\"english\"\n",
    ")\n",
    "# Join the tokenized words into a single string for each document\n",
    "tfidf = tfidf_vectorizer.fit_transform(movie_descriptions)\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Explore the TF-IDF vectors\n",
    "print(type(tfidf))\n",
    "print(tfidf.shape)\n",
    "print(tfidf_feature_names[:50])\n",
    "print(tfidf.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb72f96f",
   "metadata": {},
   "source": [
    "### 2.2 Topic Modeling (10 Marks)\n",
    "Use TF and TF-IDF representation generated in task 2.1 to perform topic modelling. Select and compare two topic modelling algorithms from LDA, Truncated SVD, Word2Vec or any other topic modelling algorithms, and then analyze the results.\n",
    "\n",
    "We Choose to compare LDA and Truncated SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e8d755",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1) LDA : Latent Dirichlet Allocation\n",
    "\n",
    "\n",
    "# Create and fit the LDA model\n",
    "n_topics = 10  # You specified n_topics separately, use it here\n",
    "LDA_model = LatentDirichletAllocation(\n",
    "    n_components=n_topics,  # Use n_topics instead of n_components\n",
    "    max_iter=5,\n",
    "    learning_method=\"online\",\n",
    "    learning_offset=50.0,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "LDA_model.fit(tfidf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc9ca28",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2) TruncatedSVD with TFIDF vectorizer\n",
    "\n",
    "\n",
    "svd = TruncatedSVD(n_components=10, n_iter=100)\n",
    "svd_topic_vectors = svd.fit_transform(tfidf)\n",
    "\n",
    "topic_terms = svd.components_\n",
    "\n",
    "# Convert the numpy array to a Pandas DataFrame\n",
    "svd_topic_vectors = pd.DataFrame(svd_topic_vectors) \n",
    "svd_topic_vectors.round(3) # Round the values to 3 decimal places\n",
    "\n",
    "\n",
    "# illustrated topics after truncated SVD: display topics and terms\n",
    "top_terms = 30\n",
    "TOTAL_TOPICS = 10 # we assume the optimal number of topics\n",
    "vocabulary = np.array(tfidf_feature_names)\n",
    "topic_key_term_idxs = np.argsort(-np.absolute(topic_terms), axis=1)[:,:top_terms]\n",
    "topic_keyterm_weights = np.array([topic_terms[row, columns] for row, columns in list(zip(np.arange(TOTAL_TOPICS), topic_key_term_idxs))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be44241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_words(model, feature_names, n_top_words, title, importance_threshold=0.05):\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(30, 15), sharex=True)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_features_ind = topic.argsort()[: -n_top_words - 1 : -1]\n",
    "        top_features = [feature_names[i] for i in top_features_ind]\n",
    "        weights = topic[top_features_ind]\n",
    "\n",
    "        # Apply threshold for topic importance to display the bars correctly\n",
    "        if weights.max() < importance_threshold:\n",
    "            continue\n",
    "\n",
    "        # Normalize weights, also helping display the bars correctly\n",
    "        weights /= weights.sum()\n",
    "\n",
    "        ax = axes[topic_idx]\n",
    "        ax.barh(top_features, weights, height=0.7)\n",
    "        ax.set_title(f\"Topic {topic_idx + 1}\", fontdict={\"fontsize\": 30})\n",
    "        ax.invert_yaxis()\n",
    "        ax.tick_params(axis=\"both\", which=\"major\", labelsize=20)\n",
    "        ax.grid(False)  # Remove the background grid\n",
    "        for i in \"top right left\".split():\n",
    "            ax.spines[i].set_visible(False)\n",
    "        fig.suptitle(title, fontsize=40)\n",
    "\n",
    "    plt.subplots_adjust(top=0.90, bottom=0.05, wspace=0.20, hspace=0.2)\n",
    "    plt.savefig('topics.png')\n",
    "    plt.show()\n",
    "    \n",
    "# Plot the topics for LDA BOTH with TF and TF-IDF\n",
    "plot_top_words(LDA_model, tfidf_feature_names, n_top_words=10, title=\"Topics in LDA model with TFIDF vector\")\n",
    "plot_top_words(LDA_model, tf_feature_names, n_top_words=10, title=\"Topics in LDA model with TF vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2095ec24",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the Topics for TruncatedSVD BOTH with TF-IDF\n",
    "svd = TruncatedSVD(n_components=10, n_iter=100)\n",
    "svd_topic_vectors = svd.fit_transform(tfidf)\n",
    "plot_top_words(svd, tfidf_feature_names, n_top_words=10, title=\"Topics in TruncatedSVD model with TFIDF vector\")\n",
    "\n",
    "# plot Topics in TruncatedSVD model with TF\n",
    "svd = TruncatedSVD(n_components=10, n_iter=100)\n",
    "svd_topic_vectors = svd.fit_transform(tf_vector.toarray())\n",
    "plot_top_words(svd, tf_feature_names, n_top_words=10, title=\"Topics in TruncatedSVD model with TF vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8d6ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4) Non-Negative Matrix Factorization(NMF):\n",
    "\n",
    "\n",
    "# Fit NMF model\n",
    "nmf_model = NMF(n_components=n_topics, init='random', random_state=42)\n",
    "nmf_topic_vectors = nmf_model.fit_transform(tfidf)\n",
    "\n",
    "# Display top words for each topic\n",
    "plot_top_words(nmf_model, tfidf_feature_names, n_top_words=10, title=\"Topics in nmf_model with TFIDF vector\")\n",
    "plot_top_words(nmf_model, tf_feature_names, n_top_words=10, title=\"Topics in nmf_model with TF vector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155a0742",
   "metadata": {},
   "source": [
    "### Model Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec715d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic perplexity\n",
    "\n",
    "\n",
    "# Create a function to compute perplexity\n",
    "def compute_perplexity_score(model, vectors):\n",
    "    if isinstance(model, LatentDirichletAllocation):\n",
    "        return model.perplexity(vectors)\n",
    "    elif isinstance(model, TruncatedSVD):\n",
    "        reconstructed = model.inverse_transform(model.transform(vectors))\n",
    "        error = np.linalg.norm(vectors - reconstructed)\n",
    "        perplexity = np.exp(error / vectors.shape[0])\n",
    "        return perplexity\n",
    "    elif isinstance(model, NMF):\n",
    "        reconstructed = model.transform(vectors) @ model.components_\n",
    "        error = np.linalg.norm(vectors - reconstructed)\n",
    "        perplexity = np.exp(error / vectors.shape[0])\n",
    "        return perplexity\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model type\")\n",
    "\n",
    "\n",
    "# Print perplexity for LDA_TF\n",
    "perplexity_score_lda_tf = compute_perplexity_score(LDA_model, tf_vector)\n",
    "print(f\"Perplexity Score for LDA_TF: {perplexity_score_lda_tf}\")\n",
    "\n",
    "# Print perplexity for LDA_TFIDF\n",
    "perplexity_score_lda_tfidf = compute_perplexity_score(LDA_model, tfidf)\n",
    "print(f\"Perplexity Score for LDA_TFIDF: {perplexity_score_lda_tfidf}\")\n",
    "\n",
    "# Print perplexity for TruncatedSVD_TF\n",
    "perplexity_score_svd_tf = compute_perplexity_score(svd, tf_vector)\n",
    "print(f\"Perplexity Score for TruncatedSVD_TF: {perplexity_score_svd_tf}\")\n",
    "\n",
    "# Print perplexity for TruncatedSVD_TFIDF\n",
    "perplexity_score_svd_tfidf = compute_perplexity_score(svd, tfidf)\n",
    "print(f\"Perplexity Score for TruncatedSVD_TFIDF: {perplexity_score_svd_tfidf}\")\n",
    "\n",
    "# Print perplexity for NMF_TF\n",
    "perplexity_score_nmf_tf = compute_perplexity_score(nmf_model, tf_vector)\n",
    "print(f\"Perplexity Score for NMF_TF: {perplexity_score_nmf_tf}\")\n",
    "\n",
    "# Print perplexity for NMF_TFIDF\n",
    "perplexity_score_nmf_tfidf = compute_perplexity_score(nmf_model, tfidf)\n",
    "print(f\"Perplexity Score for NMF_TFIDF: {perplexity_score_nmf_tfidf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2002e1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot - Perplexity Score over the models\n",
    "\n",
    "\n",
    "# Set the seaborn style\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Choose a color palette, 'husl' is a nice palette for distinct colors\n",
    "palette = sns.color_palette('husl', 3) \n",
    "\n",
    "# Perplexity scores\n",
    "perplexity_tf = [2366.208130818902, 1.0735427937935456, 1.0740484162056743]  # LDA, SVD, NMF for TF\n",
    "perplexity_tfidf = [7355.282280813201, 1.0142304178995196, 1.0142237116266126]  # LDA, SVD, NMF for TF-IDF\n",
    "\n",
    "# Names of the models\n",
    "names = ['LDA', 'Truncated SVD', 'NMF']\n",
    "\n",
    "# Set the positions and width for the bars\n",
    "positions = np.arange(len(names))\n",
    "width = 0.35\n",
    "\n",
    "# Plotting the bars\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Create bars for TF\n",
    "tf_per = ax.bar(positions - width/2, perplexity_tf, width, label='TF', color='darkseagreen')\n",
    "\n",
    "# Create bars for TF-IDF\n",
    "tfidf_per = ax.bar(positions + width/2, perplexity_tfidf, width, label='TF-IDF', color='#4361EE')\n",
    "\n",
    "# [https://stackoverflow.com/questions/58325443/how-to-annotate-bar-chart-with-values-different-to-those-from-get-height]\n",
    "# Adding the text labels on the bars\n",
    "def text_label(bars_charts):\n",
    "    for i in bars_charts:\n",
    "        height = i.get_height() #get height to get a text\n",
    "        ax.annotate('{}'.format(round(height, 2)),\n",
    "                    xy=(i.get_x() + i.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom',\n",
    "                    fontsize=10)\n",
    "\n",
    "# Adding titles and labels\n",
    "ax.set_title('Perplexity Score')\n",
    "ax.set_xlabel('Models')\n",
    "ax.set_ylabel('Perplexity Score (log scale)')\n",
    "ax.set_xticks(positions)\n",
    "ax.set_xticklabels(names)\n",
    "ax.tick_params(axis='y', labelsize=10)\n",
    "ax.tick_params(axis='x', labelsize=10)\n",
    "ax.yaxis.label.set_size(10)\n",
    "ax.xaxis.label.set_size(10)\n",
    "ax.title.set_size(11)\n",
    "ax.set_yscale('log')  # Set the y-axis to a logarithmic scale\n",
    "ax.grid(False)\n",
    "ax.legend()\n",
    "text_label(tf_per)\n",
    "text_label(tfidf_per)\n",
    "\n",
    "# Change y-axis labels to normal numbers\n",
    "ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda y, _: '{:g}'.format(y)))\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a729973f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic Stability score\n",
    "\n",
    "\n",
    "# Ignore convergence warnings\n",
    "warnings.simplefilter(\"ignore\", ConvergenceWarning)\n",
    "\n",
    "# Function to compute topic stability\n",
    "def compute_topic_stability(model, vectors, n_runs=10):\n",
    "    stability_scores = []\n",
    "\n",
    "    for _ in range(n_runs):\n",
    "        # Train the model\n",
    "        model.fit(vectors)\n",
    "\n",
    "        # Get the topic-word matrix\n",
    "        topic_word_matrix = model.components_\n",
    "\n",
    "        # Calculate cosine similarity between topics\n",
    "        cosine_similarity_matrix = cosine_similarity(topic_word_matrix)\n",
    "        stability_scores.append(np.mean(cosine_similarity_matrix))\n",
    "\n",
    "    return np.mean(stability_scores)\n",
    "\n",
    "# List of models and vectors\n",
    "models = [LDA_model, LDA_model, svd, svd, nmf_model, nmf_model]\n",
    "vectors = [tf_vector, tfidf, tf_vector, tfidf, tf_vector, tfidf]\n",
    "\n",
    "# Loop to compute and print topic stability scores\n",
    "for model, vector, model_name in zip(models, vectors, [\"LDA_TF\", \"LDA_TFIDF\", \"TruncatedSVD_TF\", \"TruncatedSVD_TFIDF\", \"NMF_TF\", \"NMF_TFIDF\"]):\n",
    "    stability_score = compute_topic_stability(model, vector)\n",
    "    print(f\"Topic Stability for {model_name}: {stability_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f876209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot - Topic stability score\n",
    "\n",
    "\n",
    "# stability score\n",
    "topic_stability_tf = [0.2409324219514124, 0.09999999999999998, 0.1449234941037762]  # LDA, SVD, NMF for TF\n",
    "topic_stability_tfidf = [0.6862930148616094, 0.10000000000000005, 0.178338990363186]  # LDA, SVD, NMF for TF-IDF\n",
    "\n",
    "# Names of the models\n",
    "names = ['LDA', 'Truncated SVD', 'NMF']\n",
    "\n",
    "# Set the positions and width for the bars\n",
    "positions = np.arange(len(names))\n",
    "width = 0.35\n",
    "\n",
    "# Plotting the bars\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Create bars for TF\n",
    "tf_topic_stability = ax.bar(positions - width/2, topic_stability_tf, width, label='TF', color='darkseagreen')\n",
    "\n",
    "# Create bars for TF-IDF\n",
    "tfidf_topic_stabilty = ax.bar(positions + width/2, topic_stability_tfidf,width, label='TF-IDF', color='#4361EE')\n",
    "\n",
    "# [https://stackoverflow.com/questions/58325443/how-to-annotate-bar-chart-with-values-different-to-those-from-get-height]\n",
    "# Adding the text labels on the bars\n",
    "def text_label(bars_charts):\n",
    "    for i in bars_charts:\n",
    "        height = i.get_height() #get height to get a text\n",
    "        ax.annotate('{}'.format(round(height, 2)),\n",
    "                    xy=(i.get_x() + i.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', \n",
    "                    fontsize=10)\n",
    "\n",
    "# Adding titles and labels\n",
    "ax.tick_params(axis='both', labelsize=10)\n",
    "ax.legend(fontsize=10)\n",
    "\n",
    "ax.set_title('Topic stability score')\n",
    "ax.set_xlabel('Models')\n",
    "ax.set_ylabel('Topic stability score')  # Removed '(log scale)' for clarity\n",
    "ax.set_xticks(positions)\n",
    "ax.set_xticklabels(names)\n",
    "ax.tick_params(axis='y', labelsize=10)\n",
    "ax.tick_params(axis='x', labelsize=10)\n",
    "ax.yaxis.label.set_size(10)\n",
    "ax.xaxis.label.set_size(10)\n",
    "ax.title.set_size(11)\n",
    "ax.set_yscale('linear')  # Set the y-axis to a linear scale (not log)\n",
    "ax.grid(False)\n",
    "ax.legend()\n",
    "text_label(tf_topic_stability)\n",
    "text_label(tfidf_topic_stabilty)\n",
    "\n",
    "# Change y-axis labels to normal numbers\n",
    "ax.yaxis.set_major_formatter(ticker.StrMethodFormatter(\"{x}\"))\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1e55df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic Diversity\n",
    "\n",
    "\n",
    "def compute_topic_diversity(model, feature_names, n_top_words=10):\n",
    "    # Get top words for each topic\n",
    "    top_words_per_topic = [feature_names[model.components_[i].argsort()[-n_top_words:][::-1]] for i in range(model.components_.shape[0])]\n",
    "    \n",
    "    # Calculate pairwise Jaccard similarity between sets of top words\n",
    "    similarities = []\n",
    "    for i in range(len(top_words_per_topic)):\n",
    "        for j in range(i + 1, len(top_words_per_topic)):\n",
    "            jaccard_similarity = len(set(top_words_per_topic[i]) & set(top_words_per_topic[j])) / len(set(top_words_per_topic[i]) | set(top_words_per_topic[j]))\n",
    "            similarities.append(jaccard_similarity)\n",
    "    \n",
    "    # Calculate average similarity\n",
    "    avg_similarity = sum(similarities) / len(similarities)\n",
    "    \n",
    "    return avg_similarity\n",
    "\n",
    "# Assuming you have a list of tokenized texts named 'tokenized_texts'\n",
    "# Make sure 'tokenized_texts' corresponds to the documents used to train your model\n",
    "\n",
    "# List of models and vectors\n",
    "models = [LDA_model, LDA_model, svd, svd, nmf_model, nmf_model]\n",
    "vectors = [tf_vector, tfidf, tf_vector, tfidf, tf_vector, tfidf]\n",
    "model_names = [\"LDA_TF\", \"LDA_TFIDF\", \"TruncatedSVD_TF\", \"TruncatedSVD_TFIDF\", \"NMF_TF\", \"NMF_TFIDF\"]\n",
    "\n",
    "# Loop to compute and print only topic diversity scores\n",
    "for model, vector, model_name in zip(models, vectors, model_names):\n",
    "    topic_diversity = compute_topic_diversity(model, tf_feature_names)\n",
    "    print(f\"Topic Diversity for {model_name}: {topic_diversity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd7ca0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot - Topic diversity score\n",
    "\n",
    "\n",
    "#Topic Diversity score\n",
    "topic_diversity_tf = [0.014035087719298244, 0.1181504960658727, 0.008187134502923975]  # LDA, SVD, NMF for TF\n",
    "topic_diversity_tfidf = [0.014035087719298244, 0.1181504960658727, 0.008187134502923975]  # LDA, SVD, NMF for TF-IDF\n",
    "\n",
    "# Names of the models\n",
    "names = ['LDA', 'Truncated SVD', 'NMF']\n",
    "\n",
    "# Set the positions and width for the bars\n",
    "positions = np.arange(len(names))\n",
    "width = 0.35\n",
    "\n",
    "# Plotting the bars\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Create bars for TF\n",
    "tf_topic_diver = ax.bar(positions - width/2, topic_diversity_tf, width, label='TF', color='darkseagreen')\n",
    "\n",
    "# Create bars for TF-IDF\n",
    "tfidf_topic_diver = ax.bar(positions + width/2, topic_diversity_tfidf,width, label='TF-IDF', color='#4361EE')\n",
    "\n",
    "# [https://stackoverflow.com/questions/58325443/how-to-annotate-bar-chart-with-values-different-to-those-from-get-height]\n",
    "# Adding the text labels on the bars\n",
    "def text_label(bars_charts):\n",
    "    for i in bars_charts:\n",
    "        height = i.get_height() #get height to get a text\n",
    "        ax.annotate('{}'.format(round(height, 2)),\n",
    "                    xy=(i.get_x() + i.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', \n",
    "                    fontsize=10)\n",
    "\n",
    "# Adding titles and labels\n",
    "ax.tick_params(axis='both', labelsize=10)\n",
    "ax.legend(fontsize=10)\n",
    "\n",
    "ax.set_title('Topic diversity score')\n",
    "ax.set_xlabel('Models')\n",
    "ax.set_ylabel('Topic diversity score')  # Removed '(log scale)' for clarity\n",
    "ax.set_xticks(positions)\n",
    "ax.set_xticklabels(names)\n",
    "ax.tick_params(axis='y', labelsize=10)\n",
    "ax.tick_params(axis='x', labelsize=10)\n",
    "ax.yaxis.label.set_size(10)\n",
    "ax.xaxis.label.set_size(10)\n",
    "ax.title.set_size(11)\n",
    "\n",
    "ax.set_yscale('linear')  # Set the y-axis to a linear scale (not log)\n",
    "ax.grid(False)\n",
    "ax.legend()\n",
    "text_label(tf_topic_diver)\n",
    "text_label(tfidf_topic_diver)\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290fd091",
   "metadata": {},
   "source": [
    "# evaluation of models \n",
    "Evaluating the performance of topic modeling, whether based on Term Frequency (TF) or Term Frequency-Inverse Document Frequency (TF-IDF), involves assessing the quality and coherence of the generated topics. Here are several common methods for evaluating topic modeling performance:\n",
    "\n",
    "Perplexity:\n",
    "\n",
    "Perplexity is a commonly used metric for assessing topic model performance. It measures how well the model predicts a held-out test set. Lower perplexity values indicate better performance. However, it's important to note that perplexity may not always correlate perfectly with the human interpretability of topics.\n",
    "\n",
    "\n",
    "Coherence Score:\n",
    "\n",
    "Coherence scores measure the semantic similarity between high-scoring words in a topic. Higher coherence scores suggest more coherent topics. Common coherence measures include Pointwise Mutual Information (PMI) and Normalized Pointwise Mutual Information (NPMI). Libraries like Gensim provide functions to compute coherence scores.\n",
    "\n",
    "Manual Inspection:\n",
    "\n",
    "Ultimately, the interpretability of topics is crucial. Manually inspecting the generated topics allows you to assess whether they make sense and align with your expectations. This involves looking at the top words in each topic and determining if they form coherent and meaningful themes.\n",
    "\n",
    "Visualization:\n",
    "\n",
    "Visualization techniques, such as t-SNE or UMAP, can be used to project high-dimensional topic distributions into 2D or 3D space. This allows you to visually inspect the separation and grouping of topics.\n",
    "\n",
    "Topic Stability:\n",
    "\n",
    "Topic stability assesses how consistent topics are across different runs or subsets of the data. This can be measured using techniques like Jaccard similarity or topic overlap.\n",
    "\n",
    "Human Evaluation:\n",
    "\n",
    "Conducting surveys or getting domain experts to evaluate the quality of topics is a valuable but resource-intensive approach. Experts can provide qualitative feedback on the relevance and coherence of topics.\n",
    "\n",
    "Topic Diversity:\n",
    "\n",
    "Assess whether topics cover a diverse range of themes or if they are too similar. A good topic model should capture diverse aspects of the dataset.\n",
    "It's essential to use a combination of these evaluation methods, as no single metric can fully capture the quality of generated topics. Additionally, the choice of evaluation metrics may depend on the specific goals of your analysis and the characteristics of your data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29393b1",
   "metadata": {},
   "source": [
    "### 2.3. Analysis Task: Searching for similar movies (30 Marks):\n",
    "\n",
    "Assume you would like to find similar movies as ‘Harry Potter and the Half-Blood Prince’ based\n",
    "on the given dataset, what would you do? Assume you already know that the user DOES NOT like\n",
    "‘Harry Potter and the Half-Blood Prince’, then which movies would you suggest the user to watch?\n",
    "Then write a report using “An example of possible report structure” shown above. Please introduce\n",
    "your solution, where minimum information should be provided as follows:\n",
    "1. Details on each step and expected inputs/outputs of each step\n",
    "2. Major algorithm to be used to solve this problem\n",
    "3. The results\n",
    "4. Analysis on the results\n",
    "Be noted that visualization should be used when exploring the data or illustrating the results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5476a938",
   "metadata": {},
   "source": [
    "# To find the similar movies to 'Harry Potter and the Half-Blood Prince'\n",
    "\n",
    "The following are the steps:\n",
    "    1. Create a DataFrame with the movie title and description\n",
    "    2. Tokenize the description\n",
    "    3. Vectorize the description (TF-IDF)\n",
    "    4. Compute Similarity (cosine similarity)\n",
    "    5. Retrieve the similar movies, or dissimilar movies \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7250905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first 3 steps have been completed as part of the previous tasks:    \n",
    "# 1. Create a DataFrame with the movie title and description\n",
    "# 2. Tokenize the description \n",
    "# 3. Vectorize the description\n",
    "tfidf_matrix = tfidf\n",
    "    \n",
    "# 4. Compute Similarity (cosine similarity)\n",
    "cosine_similarities = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# 5. Retrieve the similar movies, or dissimilar movies\n",
    "def get_similar_movies(movie_title, cosine_similarities, titles):\n",
    "    idx = titles.index(movie_title)\n",
    "    similar_scores = list(enumerate(cosine_similarities[idx]))\n",
    "    similar_scores = sorted(similar_scores, key=lambda x: x[1], reverse=True)\n",
    "    similar_movies = [(titles[i], score) for i, score in similar_scores[1:]]  # Exclude the movie itself\n",
    "    return similar_movies\n",
    "\n",
    "# Example: Find similar movies to 'Harry Potter and the Half-Blood Prince'\n",
    "movie_title = 'Harry Potter and the Half-Blood Prince'\n",
    "similar_movies = get_similar_movies(movie_title, cosine_similarities, df['title'].tolist())\n",
    "\n",
    "# Print the top similar movies\n",
    "print(f\"Movies similar to '{movie_title}':\")\n",
    "for title, score in similar_movies[:20]:\n",
    "    print(f\"{title} (Similarity Score: {score:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae42b9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot - WordCloud top titles\n",
    "\n",
    "\n",
    "# Prepare data for the word cloud\n",
    "movie_frequencies = {title: score for title, score in similar_movies}\n",
    "\n",
    "# Create and display the word cloud\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white', max_words=20)\n",
    "wordcloud.generate_from_frequencies(movie_frequencies)\n",
    "plt.figure(figsize=(15, 7.5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Top 20 Movies Similar to \"Harry Potter and the Half-Blood Prince\"')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f435a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we know that the audiance like the 'Harry Potter and the Half-Blood Prince', it is logical to focus on the Harry Potter francise.\n",
    "\n",
    "# Transform movie descriptions into TF-IDF matrix\n",
    "tfidf_matrix = tfidf\n",
    "\n",
    "# Get feature names (words) from the TF-IDF vectorizer\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Compute Similarity (cosine similarity)\n",
    "cosine_similarities = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Retrieve the similar movies, including at least one more Harry Potter movie\n",
    "def get_similar_movies(movie_title, cosine_similarities, titles, num_movies=5):\n",
    "    idx = titles.index(movie_title)\n",
    "    similar_scores = list(enumerate(cosine_similarities[idx]))\n",
    "    similar_scores = sorted(similar_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Filter out movies that are not Harry Potter movies\n",
    "    similar_movies = [(titles[i], score) for i, score in similar_scores[1:] if 'harry potter' in titles[i].lower()]\n",
    "\n",
    "    # Include at least one more Harry Potter movie if possible\n",
    "    additional_movies = [(titles[i], score) for i, score in similar_scores[1:] if 'harry potter' not in titles[i].lower()]\n",
    "    similar_movies += additional_movies[:max(0, num_movies - len(similar_movies))]\n",
    "\n",
    "    return similar_movies[:num_movies]\n",
    "\n",
    "# Example: Find similar movies to 'Harry Potter and the Half-Blood Prince'\n",
    "movie_title = 'Harry Potter and the Half-Blood Prince'\n",
    "similar_movies = get_similar_movies(movie_title, cosine_similarities, df_NLP_q1['title'].tolist())\n",
    "\n",
    "# Print the top similar movies\n",
    "print(f\"Movies similar to '{movie_title}':\")\n",
    "for title, score in similar_movies:\n",
    "    print(f\"{title} (Similarity Score: {score:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08691868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case the viewer DOES NOT like the movie, we can recommend the most dissimilar movies instead.\n",
    "\n",
    "\n",
    "# 5. Retrieve the dissimilar movies\n",
    "# Example: Find dissimilar movies to 'Harry Potter and the Half-Blood Prince'\n",
    "hated_movie_title = 'Harry Potter and the Half-Blood Prince'\n",
    "\n",
    "# Find the index of the hated movie in the titles list\n",
    "hated_movie_index = df['title'].tolist().index(hated_movie_title)\n",
    "\n",
    "# Get dissimilar movies using negative cosine similarities\n",
    "dissimilar_scores = list(enumerate(-cosine_similarities[hated_movie_index]))\n",
    "dissimilar_scores = sorted(dissimilar_scores, key=lambda x: x[1], reverse=True)\n",
    "dissimilar_movies = [(df['title'].iloc[i], score) for i, score in dissimilar_scores[1:]]  # Exclude the hated movie itself\n",
    "\n",
    "# Print the top dissimilar movies\n",
    "print(f\"Movies dissimilar to '{hated_movie_title}':\")\n",
    "for title, score in dissimilar_movies[:15]:\n",
    "    print(f\"{title} (Dissimilarity Score: {score:.3f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
